{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9045019</td>\n      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6483659</td>\n      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "test_df = pd.read_table('../static/data/naver/ratings_test.txt')\n",
    "train_df = pd.read_table('../static/data/naver/ratings_train.txt')\n",
    "train_df.head()"
   ]
  },
  {
   "source": [
    "### 데이터 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# 중복 샘플 제거\n",
    "train_df.drop_duplicates(subset=['document'], inplace=True) \n",
    "# Null 값이 존재하는 행 제거\n",
    "train_df = train_df.dropna(how = 'any') \n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Null 값이 존재하는 행 제거\n",
    "test_df = test_df.dropna(how = 'any') \n",
    "test_df.drop_duplicates(subset=['document'], inplace=True) \n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "source": [
    "### 텍스트 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글과 공백을 제외하고 모두 제거\n",
    "train_df['document'] = train_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "# 공백 제거\n",
    "train_df['document'].replace('', np.nan, inplace=True)\n",
    "# NA 제거\n",
    "train_df = train_df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['document'] = test_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_df['document'].replace('', np.nan, inplace=True)\n",
    "test_df = test_df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../static/data/naver/train_df.tsv',sep='\\t')\n",
    "test_df.to_csv('../static/data/naver/test_df.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['오다', '이렇다', '것', '도', '영화', '라고', '차라리', '뮤직비디오', '를', '만들다', '게', '나다', '뻔']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을']\n",
    "okt = Okt()\n",
    "okt.morphs('와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔', stem = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=145791.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60bb7421a6ab4f2d882137e30cddf94f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "X_train = []\n",
    "for sentence in tqdm(train_df['document']):\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화 stem => 어근으로 추정\n",
    "    temp_X = ' '.join([word for word in temp_X if not word in stopwords]) # 불용어 제거\n",
    "    X_train.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=48995.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bae4dbec6fe41b7a7034755fec4b156"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for sentence in tqdm(test_df['document']):\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화 stem => 어근으로 추정\n",
    "    temp_X = ' '.join([word for word in temp_X if not word in stopwords]) # 불용어 제거\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvector = CountVectorizer()\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "nb = MultinomialNB()\n",
    "lr_clf = LogisticRegression()\n"
   ]
  },
  {
   "source": [
    "CountVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  2.1min finished\n",
      "0.8466374119808143\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "params = {\n",
    "    'count_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'count_vect__max_df':[0.8,0.9],\n",
    "    'count_vect__min_df':[1,2],\n",
    "}\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params,cv=3,\n",
    "                            scoring='accuracy',verbose=1,n_jobs=-1)\n",
    "grid_pipe.fit(X_train,y_train)\n",
    "pred = grid_pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "print(acc)\n",
    "best_count_lr = grid_pipe.best_estimator_"
   ]
  },
  {
   "source": [
    "CountVectorizer + naive bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   33.1s finished\n",
      "0.8447392591080722\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "params = {\n",
    "    'count_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'count_vect__max_df':[0.8,0.9],\n",
    "    'count_vect__min_df':[1,2],\n",
    "}\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params,cv=3,\n",
    "                            scoring='accuracy',verbose=1,n_jobs=-1)\n",
    "grid_pipe.fit(X_train,y_train)\n",
    "pred = grid_pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "print(acc)\n",
    "best_count_nb = grid_pipe.best_estimator_"
   ]
  },
  {
   "source": [
    "TfidfVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.9min finished\n",
      "0.8448209000918461\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer()),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "params = {\n",
    "    'tfidf_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'tfidf_vect__max_df':[0.8,0.9],\n",
    "    'tfidf_vect__min_df':[1,2],\n",
    "}\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params,cv=3,\n",
    "                            scoring='accuracy',verbose=1,n_jobs=-1)\n",
    "grid_pipe.fit(X_train,y_train)\n",
    "pred = grid_pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "print(acc)\n",
    "best_tfidf_lr = grid_pipe.best_estimator_"
   ]
  },
  {
   "source": [
    "TfidfVectorizer + naive bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   33.6s finished\n",
      "0.8459434636187366\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "params = {\n",
    "    'tfidf_vect__ngram_range':[(1,1),(1,2)],\n",
    "    'tfidf_vect__max_df':[0.8,0.9],\n",
    "    'tfidf_vect__min_df':[1,2],\n",
    "}\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params,cv=3,\n",
    "                            scoring='accuracy',verbose=1,n_jobs=-1)\n",
    "grid_pipe.fit(X_train,y_train)\n",
    "pred = grid_pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "print(acc)\n",
    "best_tfidf_nb = grid_pipe.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/naver_tfidf_nb.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_count_lr, '../static/model/naver_count_lr.pkl')\n",
    "joblib.dump(best_count_nb, '../static/model/naver_count_nb.pkl')\n",
    "joblib.dump(best_tfidf_lr, '../static/model/naver_tfidf_lr.pkl')\n",
    "joblib.dump(best_tfidf_nb, '../static/model/naver_tfidf_nb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_count_lr = joblib.load('../static/model/naver_count_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "naver_count_lr.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['굳다', '', 'ㅋ']"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "test_data = []\n",
    "for sentence in test_df['document'][0]:\n",
    "            temp_X = []\n",
    "            temp_X = okt.morphs(sentence, stem=True)\n",
    "            temp_X = ' '.join([word for word in temp_X if not word in stopwords]) \n",
    "            test_data.append(temp_X)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "naver_count_lr.predict(test_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}